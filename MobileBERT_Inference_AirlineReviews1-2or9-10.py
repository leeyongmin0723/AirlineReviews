import pandas as pd
import torch
import numpy as np
from transformers import MobileBertTokenizer, MobileBertForSequenceClassification
from tqdm import tqdm
from sklearn.metrics import classification_report

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv("AirlineReviews_EngClean_1-2vs9-10_remaining.csv")
df = df[df['Review'].notna()]  # ê²°ì¸¡ì¹˜ ì œê±°

texts = df['Review'].astype(str).tolist()
true_labels = df['label'].tolist()

# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ
model_path = "./mobilebert_1-2vs9-10_5000_e10"
tokenizer = MobileBertTokenizer.from_pretrained(model_path)
model = MobileBertForSequenceClassification.from_pretrained(model_path)
model.to(device)
model.eval()

# í† í¬ë‚˜ì´ì§•
inputs = tokenizer(texts, truncation=True, padding=True, max_length=256, return_tensors="pt")
input_ids = inputs["input_ids"]
attention_mask = inputs["attention_mask"]

# ë°°ì¹˜ ì²˜ë¦¬
batch_size = 32
test_dataset = torch.utils.data.TensorDataset(input_ids, attention_mask, torch.tensor(true_labels))
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)

# Inference
all_preds = []
all_true = []

for batch in tqdm(test_loader, desc="Running Inference"):
    b_input_ids, b_mask, b_labels = [b.to(device) for b in batch]

    with torch.no_grad():
        outputs = model(input_ids=b_input_ids, attention_mask=b_mask)
        preds = torch.argmax(outputs.logits, dim=1)

    all_preds.extend(preds.cpu().numpy())
    all_true.extend(b_labels.cpu().numpy())

# ì •í™•ë„ ë° ë¦¬í¬íŠ¸ ì¶œë ¥
accuracy = np.mean(np.array(all_preds) == np.array(all_true))
print(f"\nâœ… ê°ì • ë¶„ë¥˜ ì •í™•ë„: {accuracy:.4f}\n")

print("ğŸ“Š ë¶„ë¥˜ ë¦¬í¬íŠ¸:")
print(classification_report(all_true, all_preds, target_names=["ë¶€ì •", "ê¸ì •"]))
